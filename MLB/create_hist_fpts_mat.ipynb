{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: set covariance to 0 if less than played in less than 10% of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "os.chdir(\"/Users/alandu/Documents/DFS/\")\n",
    "# from datetime import date, timedelta\n",
    "import datetime\n",
    "from pathlib import Path\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dateRange(start, end, delta):\n",
    "    dates = []\n",
    "    curr = start\n",
    "    while curr < end:\n",
    "        dates.append(curr)\n",
    "        curr += delta\n",
    "    dates = list(dates)\n",
    "#     output = [date.strftime('%Y-%m-%d') for date in dates]\n",
    "    return dates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create first/base case hist_fpts_mat_update matrix (only need to run once at beginning of season)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # first date\n",
    "# date = \"2017-04-02\"\n",
    "\n",
    "# results_mat = pd.read_csv(\"MLB/data_warehouse/\" + date + \"/player_results.csv\")\n",
    "# results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "# results_mat = results_mat[['Name_Team', 'Actual Score']]\n",
    "# results_mat.rename(columns={'Actual Score':date}, inplace = True)\n",
    "# results_mat\n",
    "\n",
    "# results_mat.to_csv(\"MLB/data_warehouse/\" + \"2017-04-03\" + \"/hist_fpts_mat_update.csv\", index=False, na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create hist_fpts_mat_update for rest of season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "date missing after 2017-07-10\n",
      "date missing after 2017-07-14\n",
      "date missing after 2017-07-17\n",
      "date missing after 2017-08-09\n"
     ]
    }
   ],
   "source": [
    "# this code could be cleaned up. got messy because missing some date folders due to missing data / all star break\n",
    "\n",
    "# rest of dates\n",
    "date_list = dateRange(datetime.date(2017, 4, 4), datetime.date(2017, 8, 15), datetime.timedelta(days=1))\n",
    "\n",
    "for date in date_list:\n",
    "    file_path_date = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d'))\n",
    "    if file_path_date.exists():\n",
    "        date_tm1 = date - datetime.timedelta(days=1)\n",
    "        \n",
    "        # read in hist_fpts_mat_update from date t-1\n",
    "        file_path_hist = Path(\"MLB/data_warehouse/\" + date_tm1.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "        if file_path_hist.exists():\n",
    "            hist_fpts_mat = pd.read_csv(str(file_path_hist))\n",
    "        else:\n",
    "            # fill in dates where folder is missing\n",
    "            temp_date = date_tm1 - datetime.timedelta(days=1)\n",
    "            file_path_hist = Path(\"MLB/data_warehouse/\" + temp_date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "            num_missing = 1\n",
    "            while (file_path_hist.exists() == False):\n",
    "                temp_date = temp_date - datetime.timedelta(days=1)\n",
    "                file_path_hist = Path(\"MLB/data_warehouse/\" + temp_date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "                num_missing += 1\n",
    "            hist_fpts_mat = pd.read_csv(str(file_path_hist))\n",
    "            print(\"date(s) missing after \" + date.strftime('%Y-%m-%d'))\n",
    "            for i in range(0,num_missing):\n",
    "                new_column = temp_date + datetime.timedelta(days=i+1)\n",
    "                \n",
    "                # add missing date\n",
    "                new_column_m1 = new_column - datetime.timedelta(days=1)\n",
    "#                 print(new_column_m1.strftime('%Y-%m-%d'))\n",
    "                file_path_results = Path(\"MLB/data_warehouse/\" + new_column_m1.strftime('%Y-%m-%d') + \"/player_results.csv\")\n",
    "                if file_path_results.exists():\n",
    "                    results_mat = pd.read_csv(str(file_path_results))\n",
    "                    results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "                    hist_fpts_mat = hist_fpts_mat.merge(results_mat[['Name_Team', 'Actual Score']], on=\"Name_Team\", how='outer')\n",
    "                    hist_fpts_mat.rename(columns={'Actual Score':new_column_m1.strftime('%Y-%m-%d')}, inplace = True)\n",
    "                elif Path(\"MLB/data_warehouse/\" + new_column_m1.strftime('%Y-%m-%d')).exists():\n",
    "                    hist_fpts_mat[new_column_m1.strftime('%Y-%m-%d')] = float('NaN')\n",
    "                \n",
    "                # add previous dates NA\n",
    "                hist_fpts_mat[new_column.strftime('%Y-%m-%d')] = float('NaN')\n",
    "        \n",
    "        # add fpts for date t\n",
    "        file_path_results = Path(\"MLB/data_warehouse/\" + date_tm1.strftime('%Y-%m-%d') + \"/player_results.csv\")\n",
    "        if file_path_results.exists():\n",
    "            results_mat = pd.read_csv(str(file_path_results))\n",
    "            results_mat['Name_Team'] = results_mat['Player'] + \"_\" + results_mat['Team']\n",
    "\n",
    "            new_hist_fpts_mat = hist_fpts_mat.merge(results_mat[['Name_Team', 'Actual Score']], on=\"Name_Team\", how='outer')\n",
    "            new_hist_fpts_mat.rename(columns={'Actual Score':date_tm1.strftime('%Y-%m-%d')}, inplace = True)\n",
    "        else:\n",
    "            new_hist_fpts_mat = hist_fpts_mat\n",
    "            new_hist_fpts_mat[date_tm1.strftime('%Y-%m-%d')] = float('NaN')\n",
    "        \n",
    "        # write to file\n",
    "        new_hist_fpts_mat.to_csv(str(file_path_date) + \"/hist_fpts_mat_update.csv\", index=False, na_rep=\"NA\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create full covariance matrix for entire season"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "date_list = dateRange(datetime.date(2017, 4, 4), datetime.date(2017, 8, 15), datetime.timedelta(days=1))\n",
    "for date in date_list:\n",
    "    # create covariance matrix\n",
    "    file_path_hist = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "    if file_path_hist.exists():\n",
    "        hist_fpts_mat_update = pd.read_csv(str(file_path_hist), header=None)\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update[1:] # remove first row (header)\n",
    "\n",
    "        player_team_vec = hist_fpts_mat_update[0]\n",
    "        player_team_vec = player_team_vec.reset_index(drop=True)\n",
    "\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update.drop(0, 1) # remove first column (names)\n",
    "        hist_fpts_mat_update = hist_fpts_mat_update.astype(float)\n",
    "        cov_mat_masked = np.ma.array(hist_fpts_mat_update, mask=np.isnan(hist_fpts_mat_update))\n",
    "        cov_mat = np.ma.cov(cov_mat_masked, allow_masked=True)\n",
    "        cov_mat = np.ma.getdata(cov_mat)\n",
    "        \n",
    "        # get list of team names in order\n",
    "        column_teams = []\n",
    "        for player_team in player_team_vec:\n",
    "            column_teams.append(player_team.split('_')[1])\n",
    "\n",
    "        # set covariance to 0 if not on same team\n",
    "        for ind_row, player_team in enumerate(player_team_vec):\n",
    "            row_team = player_team_vec[ind_row].split('_')[1]\n",
    "            for ind_col, column_team in enumerate(column_teams):\n",
    "                if row_team != column_team:\n",
    "                    cov_mat[ind_row, ind_col] = 0.0\n",
    "                    \n",
    "        # TODO: set to 0 if less than played in less than 5% of games\n",
    "                    \n",
    "        # convert to pandas df to add column names\n",
    "        cov_mat = pd.DataFrame(cov_mat)\n",
    "        cov_mat.columns = player_team_vec\n",
    "        \n",
    "        # write to file\n",
    "        cov_mat.to_csv(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/covariance_mat_update.csv\", index=False, na_rep=\"NA\")\n",
    "        print(date.strftime('%Y-%m-%d') + \" completed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Subset covariance matrix for each contest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2017-07-31 $6.00entry_MLB$350KSwingfortheFences[$50Kto1st] completed\n",
      "2017-07-31 $444.00entry_MLB$425KGrandSlam[$100Kto1st!] completed\n",
      "2017-07-31 $55.00entry_MLB$300KFullCount[$50Kto1st] completed\n",
      "2017-07-31 $33.00entry_$4MFantasyBaseballWorldChampionshipQualifier#102 completed\n",
      "2017-07-31 $4.00entry_MLB$40KFour-Seamer[20EntryMax] completed\n",
      "2017-07-31 $25.00entry_MLB$25DoubleUp completed\n",
      "2017-07-31 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-07-31 $5.00entry_MLB$5DoubleUp completed\n",
      "2017-07-31 $2.00entry_MLB$2DoubleUp completed\n",
      "2017-07-31 $3.00entry_MLB$3KMoonshot completed\n",
      "2017-07-31 $2.00entry_MLB$4KFlare completed\n",
      "2017-07-31 $1.00entry_MLB$10KSoloShot completed\n",
      "2017-07-31 $0.25entry_MLB$2KQuarterJukebox[Just$0.25!] completed\n",
      "2017-07-31 $0.10entry_MLB$3KDimeTime[Just$0.10!] completed\n",
      "2017-07-31 $0.10entry_MLB$2KDimeTime[Just$0.10!] completed\n",
      "2017-07-31 $0.25entry_MLB$200Jukebox(AllDay) completed\n",
      "2017-07-31 $0.10entry_MLB$100DimeTime[Just$0.10!](AllDay) completed\n",
      "2017-07-31 $8.00entry_MLB$15KRallyCap(Night) completed\n",
      "2017-07-31 $4.00entry_MLB$7KFour-Seamer[20EntryMax](Night) completed\n",
      "2017-07-31 $2.00entry_MLB$1KFlare(Night) completed\n",
      "2017-07-31 $1.00entry_MLB$2KSoloShot(Night) completed\n",
      "2017-07-31 $0.25entry_MLB$1KQuarterJukebox[Just$0.25!](Night) completed\n",
      "2017-07-31 $0.10entry_MLB$100DimeTime[Just$0.10!](Night) completed\n"
     ]
    }
   ],
   "source": [
    "date_list = dateRange(datetime.date(2017, 7, 31), datetime.date(2017, 8, 1), datetime.timedelta(days=1))\n",
    "\n",
    "for date in date_list:\n",
    "    # read in contests.csv and subset by date\n",
    "    contests_file = pd.read_csv(\"MLB/data_warehouse/contests.csv\")\n",
    "    contests_file = contests_file[(contests_file['Contest_Date'] == date.strftime('%Y-%m-%d'))]\n",
    "    contests_file = contests_file.reset_index()\n",
    "    \n",
    "    for i in range(0, len(contests_file)):\n",
    "        file_path_hist = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/hist_fpts_mat_update.csv\")\n",
    "        file_path_date = Path(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d'))\n",
    "        if file_path_hist.exists():\n",
    "            # read in hist_fpts_mat_update (don't actually need this but used for convenience of column names)\n",
    "            hist_fpts_mat_update = pd.read_csv(str(file_path_hist), header=None)\n",
    "\n",
    "            # read in hitters.csv\n",
    "            contest_name = contests_file['Entry_Fee'][i] + \"entry_\" + contests_file['Contest_Name'][i].replace(\" \", \"\")\n",
    "            file_path_hitters =  Path(str(file_path_date) + \"/\" + contest_name + \"/hitters.csv\")\n",
    "            if file_path_hitters.exists():\n",
    "                hitters_df = pd.read_csv(str(file_path_date) + \"/\" + contest_name + \"/hitters.csv\")\n",
    "\n",
    "                # read in covariance_mat_update and update it\n",
    "                covariance_mat_update = pd.read_csv(str(file_path_date) + \"/covariance_mat_update.csv\")\n",
    "\n",
    "                # find indicies of each player in hitters_df in hist_fpts_mat_update\n",
    "                hitters_name_team = hitters_df['Name'] + \"_\" + hitters_df['teamAbbrev']\n",
    "                inds_match = []\n",
    "                for name_team in hitters_name_team:\n",
    "                    inds_match.append(hist_fpts_mat_update[hist_fpts_mat_update[0] == name_team].index.tolist())\n",
    "\n",
    "                # find indicies of missing players (will be 0's in covariance matrix)\n",
    "                inds_missing = []\n",
    "                for i, ind in enumerate(inds_match):\n",
    "                    if (len(ind) == 0):\n",
    "                        inds_missing.append(i)\n",
    "\n",
    "                # append 0's to covariance matrix\n",
    "                inds_added = []\n",
    "                for i in range(0,len(inds_missing)):\n",
    "                    covariance_mat_update.loc[len(covariance_mat_update)] = 0\n",
    "                    covariance_mat_update[len(covariance_mat_update)] = pd.Series(np.zeros(len(covariance_mat_update)), index=covariance_mat_update.index)\n",
    "                    inds_added.append(len(covariance_mat_update)-1)\n",
    "\n",
    "                # fill in inds where no match\n",
    "                for i, ind in enumerate(inds_missing):\n",
    "                    inds_match[ind] = [inds_added[i]]\n",
    "\n",
    "                # unlist for numpy function\n",
    "                inds_match = sum(inds_match, [])\n",
    "\n",
    "                # update covariance matrix\n",
    "                covariance_mat_update = np.array(covariance_mat_update)\n",
    "                covariance_mat_update = covariance_mat_update[np.ix_(inds_match,inds_match)] # subset nxn matrix into mxm\n",
    "                covariance_mat_update = pd.DataFrame(covariance_mat_update)\n",
    "                covariance_mat_update.columns = hitters_name_team # set column names\n",
    "\n",
    "                # write to file\n",
    "                covariance_mat_update.to_csv(\"MLB/data_warehouse/\" + date.strftime('%Y-%m-%d') + \"/\" + contest_name + \"/covariance_mat_update.csv\", index=False, na_rep=\"NA\")\n",
    "\n",
    "                # print\n",
    "                print(date.strftime('%Y-%m-%d') + \" \" + contest_name + \" completed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
